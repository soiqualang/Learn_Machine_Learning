{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soiqualang/Learn_Machine_Learning/blob/master/ml1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wuXC7leKjqpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "fc48267f-8bef-4eeb-e814-7340b5bbb855"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/soiqualang/machine-learning-repo/develop/regression/home_data.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-04 11:12:28--  https://raw.githubusercontent.com/soiqualang/machine-learning-repo/develop/regression/home_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50158 (49K) [text/plain]\n",
            "Saving to: ‘home_data.csv’\n",
            "\n",
            "\rhome_data.csv         0%[                    ]       0  --.-KB/s               \rhome_data.csv       100%[===================>]  48.98K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-01-04 11:12:28 (3.49 MB/s) - ‘home_data.csv’ saved [50158/50158]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yMKAXgZGkLWx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Bài này mình tham khảo ở đây\n",
        "https://viblo.asia/p/mo-hinh-hoi-quy-ung-dung-trong-bai-toan-du-doan-gia-bat-dong-san-machine-learning-phan-2-xQMkJLrzGam\n",
        "\n",
        "Repo\n",
        "https://github.com/soiqualang/machine-learning-repo/tree/develop/regression"
      ]
    },
    {
      "metadata": {
        "id": "ZzdPtApRlGqJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ứng dụng vào bài toán dự đoán giá bất động sản\n",
        "Cái đầu tiên muốn nói gì thì nói chúng ta cần phải có một tập dữ liệu.Tập dữ liệu trong bài viết này các bạn có thể tìm thấy ở đây. File CSV này chứa thông tin về các bất động sản như số phòng ngủ, số phòng tắm, năm xây dựng... và giá bán tương ứng của nó. Chúng ta sẽ áp dụng lý thuyết về mô hình hồi quy để từ tập dữ liệu này, xây dựng một hàm sử dụng để định giá cho một bất động sản bất kì trong tương lai. OK chúng ta bắt đầu thôi."
      ]
    },
    {
      "metadata": {
        "id": "wswvLjsflKth",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Đọc dữ liệu từ file CSV\n",
        "Trước tiên các bạn cần cài đặt Python và các thư viện cần thiết. Như phiên bản hiện tại mình đang sử dụng là Python 2.7 và Scikit-learn 0.18.1. Sau khi cài đặt các môi trường cần thiết. Chúng ta hãy viết một hàm để load dữ liệu từ file CSV bên trên như sau:"
      ]
    },
    {
      "metadata": {
        "id": "17WS6nU9kGwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BW93W4WKkWe3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getData():\n",
        "    # Get home data from CSV file\n",
        "    dataFile = None\n",
        "    if os.path.exists('home_data.csv'):\n",
        "        print(\"-- home_data.csv found locally\")\n",
        "        #dataFile = pd.read_csv('home_data.csv', skipfooter=1)\n",
        "        dataFile = pd.read_csv('home_data.csv', skipfooter=1,engine='python')\n",
        "    return dataFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i4g3uACFlO4v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hàm trên sử dụng thư viện Pandas để load dữ liệu từ file CSV vào dưới dạng DataFrame"
      ]
    },
    {
      "metadata": {
        "id": "IHNnn-_Wkbo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4933f618-b47b-448f-a908-6b5f4e0c2113"
      },
      "cell_type": "code",
      "source": [
        "dataFile = pd.read_csv('home_data.csv', skipfooter=1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "21qzAL5zkhO_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataFile = pd.read_csv('home_data.csv', skipfooter=1,engine='python')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cAkNKPu-lSiY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lựa chọn thuộc tính và phân chia tập dữ liệu mẫu\n",
        "Tư tưởng của chúng ta là sẽ phân chia tập dữ liệu mẫu thành hai tập con là tập dữ liệu huấn luyện và tập dữ liệu kiểm tra. Việc này sử dụng tư tưởng của kiểm tra chéo (cross validation). Ngoài ra, trong tập dữ liệu mẫu có rất nhiều thuộc tính có ý nghĩa và có thể khai thác thêm, ví dụ như từ kinh độ và vĩ độ chúng ta có thể tìm thêm các thuộc tính như khoảng cách trung tâm thành phố, số bệnh viện lân cận... Tuy nhiên trong bài viết này để cho đơn giản, mình lựa chọn một cách chủ quan một số thuộc tính mà mình cho rằng có thể có ảnh hưởng đến giá của bất động sản như số phòng ngủ, số phòng tắm, năm xây dựng và diện tích... Tất nhiên rằng, lựa chọn thuộc tính là một bài toán khác trong học máy, các bạn có thể tham khảo ở đây nhưng trong phạm vi bài viết này chúng ta chưa bàn đến nó."
      ]
    },
    {
      "metadata": {
        "id": "FeYGS9Efk3jg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cce48f92-c3f1-4133-aff3-d9de00e67384"
      },
      "cell_type": "code",
      "source": [
        "data = getData()\n",
        "if data is not None:\n",
        "\t# Selection few attributes\n",
        "\tattributes = list(\n",
        "\t\t[\n",
        "\t\t\t'num_bed',\n",
        "\t\t\t'year_built',\n",
        "\t\t\t'num_room',\n",
        "\t\t\t'num_bath',\n",
        "\t\t\t'living_area',\n",
        "\t\t]\n",
        "\t)\n",
        "\t# Vector price of house\n",
        "\tY = data['askprice']\n",
        "\t# Vector attributes of house\n",
        "\tX = data[attributes]\n",
        "\t# Split data to training test and testing test\n",
        "\tX_train, X_test, Y_train, Y_test = train_test_split(np.array(X), np.array(Y), test_size=0.2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- home_data.csv found locally\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uKd7PptfmOQo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Áp dụng mô hình hồi quy tuyến tính\n",
        "Về cơ bản, việc huấn luyện theo mô hình tuyến tính bản chất là đi tìm các giá trị m và b sao cho cực tiểu hóa hàm lỗi sau: alt\n",
        "\n",
        "Chúng ta sử dụng gói thư viện Scikit-learn của Python để làm việc này rất đơn giản như sau:"
      ]
    },
    {
      "metadata": {
        "id": "hbCkNcUnlbs4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def linearRegressionModel(X_train, Y_train, X_test, Y_test):\n",
        "    linear = linear_model.LinearRegression()\n",
        "    # Training process\n",
        "    linear.fit(X_train, Y_train)\n",
        "    # Evaluating the model\n",
        "    score_trained = linear.score(X_test, Y_test)\n",
        "\n",
        "    return score_trained"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sOWiOiQAmRsJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hàm trên chạy mô hình hồi quy tuyến tính trên tập dữ liệu huấn luyện gồm X_train đại diện cho tập các thuộc tính của bất động sản và Y_train đại diện cho giá của nhà. Hàm trả về một giá trị đánh giá điểm của mô hình khi chạy trên tập kiểm tra. Về cơ bản, chúng ta có thể sử dụng điểm này để so sánh giữa các phương pháp hồi quy khác sẽ trình bày ở phần tiếp theo. Có nghĩa là điểm càng tiến gần đến 1 thì mô hình của chúng ta càng tốt."
      ]
    },
    {
      "metadata": {
        "id": "klklBT7rmVMv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Áp dụng mô hình hồi quy LASSO dạng chuẩn L1\n",
        "Các dạng chuẩn (Regularization) thường được đưa vào các mô hình để nhằm giảm thiểu hiện tượng over-fitting. Nói về overfitting là cả một câu chuyện dài và mình hứa sẽ có dịp kể cho các bạn nghe về câu chuyện đó trên Viblo này. Chúng ta có thể hiểu nôm na như sau, một mô hình của chúng ta lựa chọn đang cố gắng giảm thiểu tối đa lỗi trên tập dữ liệu huấn luyện nhưng nó lại làm cho lỗi trên tập dữ liệu kiểm tra tăng lên. Và LASSO ra đời để hạn chế điều đó. Nó bổ sung thêm vào hàm lỗi của mô hình tuyến tính một đại lượng phạt lỗi lamda. Từ đó mô hình của chúng ta sẽ tìm các tham số phù hợp sao cho cực tiểu hóa hàm lỗi như sau:\n",
        "\n",
        "alt\n",
        "\n",
        "Chúng ta sẽ viết một hàm tính toán điểm của phương pháp LASSO như sau:"
      ]
    },
    {
      "metadata": {
        "id": "xnutEOWjmPl3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lassoRegressionModel(X_train, Y_train, X_test, Y_test):\n",
        "    lasso_linear = linear_model.Lasso(alpha=1.0)\n",
        "    # Training process\n",
        "    lasso_linear.fit(X_train, Y_train)\n",
        "    # Evaluating the model\n",
        "    score_trained = lasso_linear.score(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pwTSw2BCmdKo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Đánh giá hai mô hình hồi quy vừa áp dụng\n",
        "Trong hàm main chúng ta chạy và so sánh hai hàm như sau:"
      ]
    },
    {
      "metadata": {
        "id": "NRkaQDNlmXwP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "35b68a77-636a-4281-e701-87b2befd5db1"
      },
      "cell_type": "code",
      "source": [
        "if data is not None:\n",
        "        # Selection few attributes\n",
        "        attributes = list(\n",
        "            [\n",
        "                'num_bed',\n",
        "                'year_built',\n",
        "                'num_room',\n",
        "                'num_bath',\n",
        "                'living_area',\n",
        "            ]\n",
        "        )\n",
        "        # Vector price of house\n",
        "        Y = data['askprice']\n",
        "        # print np.array(Y)\n",
        "        # Vector attributes of house\n",
        "        X = data[attributes]\n",
        "        # Split data to training test and testing test\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(np.array(X), np.array(Y), test_size=0.2)\n",
        "        # Linear Regression Model\n",
        "        linearScore = linearRegressionModel(X_train, Y_train, X_test, Y_test)\n",
        "        print 'Linear Score = ' , linearScore\n",
        "        # LASSO Regression Model\n",
        "        lassoScore = lassoRegressionModel(X_train, Y_train, X_test, Y_test)\n",
        "        print 'Lasso Score = ', lassoScore"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Score =  0.5247902368532621\n",
            "Lasso Score =  None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CK2C0yDVm5hJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nếu dữ liệu và số lượng thuộc tính đủ lớn, ta có thể quan sát rõ tốc độ hội tụ của phương pháp Lasso nhanh hơn phương pháp hồi quy tuyến tính, nhờ vào cơ chế tính đạo hàm cho từng thuộc tính thay vì tính đạo hàm cùng lúc cho các thuộc tính. Cuối cùng, việc lựa chọn mô hình được dựa vào chỉ số đánh giá mô hình. Mô hình càng tốt thì model score càng gần đến 1.0.\n",
        "\n",
        "Kết luận\n",
        "Hồi quy là một phương pháp đơn giản và dễ áp dụng trong thực tế. Thực ra bài toán này còn có thể cải thiện hơn được nữa nhờ vào việc xấp xỉ căn bậc hai cho mô hình hay còn gọi là kĩ thuật nâng bậc cho mô hình tuyến tính mình sẽ tiếp tục trình bày trong các bài tiếp theo. Chúc các bạn cuối tuần vui vẻ. Xin chào tạm biệt và hẹn gặp lại."
      ]
    },
    {
      "metadata": {
        "id": "62b-PbY_mpYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}